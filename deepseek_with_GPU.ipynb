{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e23819",
   "metadata": {},
   "source": [
    "## This is GPU based machines.\n",
    "### Install required modules\n",
    "Use existing package managers (Conda, UV, Pip) to install required modules.\n",
    "Ran this model on a CPU based Server, with 64 GB RAM and for inferencing CPU as 100% for more than 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218d735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import accelerate\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc36171",
   "metadata": {},
   "source": [
    "### Check version of Torch and is Torch enabled with GPU.\n",
    "CUDA libraries are developed by NVidia and Pytorch are python abstractions over NVidia CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7ab5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch.version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcf71d",
   "metadata": {},
   "source": [
    "### Hugging Face API\n",
    "1. Create Hugging Face Account if not already exists.\n",
    "2. Create API Token\n",
    "3. Configure token in .env file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaaa6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2631be",
   "metadata": {},
   "source": [
    "Function: Load Model\n",
    "1. Given a model name\n",
    "2. From HF model hub, loads the model in memory.\n",
    "\n",
    "Note: \n",
    "1. When model is loaded it uses GPU / CPU based on avilable compute resources.\n",
    "2. By default, pytorch uses datatype of weights as FP32.\n",
    "3. On GPUs, loading models may fail if they exceed GPU memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7612d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(\n",
    "                    model_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "                    ):\n",
    "    quantification_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    bnb_4bit_quant_type='fp4'\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        # device_map=,\n",
    "        quantization_config=quantification_config,  #! Quantization\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b105e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:38<00:00, 24.59s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\"\n",
    "model, tokenizer = load_model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b9b4",
   "metadata": {},
   "source": [
    "Review the number of parameters and size of the model (7 GB as against the base model with 30 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96471af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameter: 8030261248 and approximate size of model 7 GBs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Model Parameter: {model.num_parameters()} and approximate size of model {round(model.num_parameters()*1/1024/1024/1024)} GBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d140f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.0.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.0.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.1.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.1.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.2.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.2.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.3.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.3.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.4.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.4.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.5.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.5.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.6.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.6.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.7.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.7.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.8.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.8.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.9.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.9.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.10.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.10.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.11.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.11.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.12.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.12.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.13.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.13.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.14.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.14.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.15.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.15.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.16.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.16.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.17.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.17.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.18.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.18.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.19.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.19.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.20.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.20.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.21.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.21.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.22.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.22.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.23.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.23.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.24.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.24.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.25.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.25.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.26.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.26.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.27.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.27.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.28.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.28.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.29.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.29.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.30.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.30.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.31.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.31.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.norm.weight is loaded with torch.float16 and device type cuda:0\n",
      "lm_head.weight is loaded with torch.float16 and device type cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is loaded with {param.dtype} and device type {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f02d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743903a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_response(\n",
    "        prompt:str,\n",
    "        tokenizer:AutoTokenizer,\n",
    "        model:AutoModelForCausalLM,\n",
    "        max_length:int=3500,\n",
    "        temperature:float=0.1,\n",
    "        top_k:int=50)->str:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\",padding=True)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = {k: v.to(device) for k, v in input_ids.items()}\n",
    "    print(inputs)\n",
    "    attention_mask = input_ids[\"attention_mask\"]\n",
    "    input_ids = input_ids[\"input_ids\"]\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    print(attention_mask[0])\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        output = model.generate(\n",
    "                                    **inputs, \n",
    "                                    max_length=max_length, \n",
    "                                    do_sample=True,\n",
    "                                    temperature=temperature, \n",
    "                                    top_k=top_k,\n",
    "                                    # attention_mask=attention_mask,\n",
    "                                    pad_token_id=pad_token_id,\n",
    "                                    eos_token_id=eos_token_id\n",
    "                                    )\n",
    "        final_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        print(final_output)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52583a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000,   3923,    374,    279,   7438,    315,   2324,     30]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "What is the meaning of life? That's a big question. I think it's different for everyone. For me, I guess it's about finding purpose and being happy. But I'm not entirely sure. Maybe it's about helping others or making a difference in the world. Or maybe it's just about enjoying the journey. I'm still figuring it out.\n",
      "Okay, so I'm trying to figure out the meaning of life. I know different people have different answers, so I shouldn't be too strict about it. For me, I think it's about finding my purpose and being happy. But I'm not entirely sure if that's the right approach. Maybe it's more about helping others or making a difference in the world. Or maybe it's just about enjoying the journey. I'm still figuring it out.\n",
      "\n",
      "I remember hearing that some people find their purpose through their careers or hobbies. Like, if you love what you do, that gives you a sense of purpose. But then there are others who find their purpose through their relationships or personal growth. It seems like it can vary so much.\n",
      "\n",
      "I also think about the bigger picture. Is there a universal meaning, or is it all relative? Maybe it's different for each culture or each individual. That makes sense because cultures have different values and beliefs, so their meanings of life would reflect that.\n",
      "\n",
      "But then, how do I find my own meaning? Maybe I need to explore what makes me happy and what I'm passionate about. It might take some time and experimentation. Trying different things to see what resonates with me.\n",
      "\n",
      "I also wonder if it's possible to have multiple meanings. Like, maybe one aspect is about personal growth, and another is about helping others. Or maybe it's a combination of both. It could be that the meaning of life isn't just one thing, but a collection of experiences and values that come together to give life meaning.\n",
      "\n",
      "Another thought: some people find their meaning through spirituality or religion. They might believe that the meaning is defined by their faith or beliefs. Others might not rely on religion but still find meaning through other sources like nature or art.\n",
      "\n",
      "I'm also thinking about the idea of the journey. Maybe the meaning isn't something to be found, but something to be experienced. It's about the process of living and the experiences along the way that bring fulfillment.\n",
      "\n",
      "But then, how do I know if I'm on the right track? Or if I'm missing something? Maybe it's about reflection. Taking time to reflect on my life, my achievements, my failures, and seeing what stands out as important or fulfilling.\n",
      "\n",
      "I also think about the concept of purpose versus happiness. Some people might prioritize purpose, like making a significant impact, while others might focus on their personal happiness and well-being. It's interesting how those can sometimes be in tension with each other.\n",
      "\n",
      "Maybe the meaning of life isn't one-size-fits-all, and that's okay. Each person's journey is unique, so their meaning of life should reflect that uniqueness. It's about embracing the differences and accepting that what gives life meaning to one person might not work for another.\n",
      "\n",
      "I also recall that some theories suggest that the meaning of life is something we create for ourselves. It's not something that's given, but something we have to discover and define. That makes me think that the process of seeking meaning is as important as the meaning itself.\n",
      "\n",
      "But then, is there a risk of overthinking it? Maybe trying too hard to find a meaning could lead to stress or dissatisfaction if it's not the right approach. It might be better to focus on the present and find joy in the little things.\n",
      "\n",
      "In summary, the meaning of life seems to be a deeply personal journey. It's about finding what brings you fulfillment, what you're passionate about, and what gives you a sense of purpose. It can be related to your career, relationships, personal growth, spirituality, or simply enjoying the journey. Each person's meaning is unique, and it's okay if it takes time to figure it out. The important thing is to keep exploring and finding what resonates with you.\n",
      "</think>\n",
      "\n",
      "The meaning of life is a deeply personal and unique journey for each individual. It is not a one-size-fits-all answer but rather a collection of experiences, values, and passions that bring fulfillment. For some, it may be found through their career or hobbies, while for others, it might emerge from relationships or personal growth. It can also be shaped by spirituality, nature, or art. The journey involves exploration and experimentation, allowing individuals to discover what resonates with them. Each person's uniqueness dictates their meaning, and it's acceptable to evolve and change over time. The key is to embrace the process, find joy in the present, and accept that the meaning of life is something we create and discover as we live it.\n",
      "Time taken: 1485.756799697876\n"
     ]
    }
   ],
   "source": [
    "generate_model_response(\"What is the meaning of life?\", tokenizer=tokenizer, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
