{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e23819",
   "metadata": {},
   "source": [
    "## This is GPU based machines.\n",
    "### Install required modules\n",
    "Use existing package managers (Conda, UV, Pip) to install required modules.\n",
    "Ran this model on a CPU based Server, with 64 GB RAM and for inferencing CPU as 100% for more than 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218d735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import accelerate\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc36171",
   "metadata": {},
   "source": [
    "### Check version of Torch and is Torch enabled with GPU.\n",
    "CUDA libraries are developed by NVidia and Pytorch are python abstractions over NVidia CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ab5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch.version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcf71d",
   "metadata": {},
   "source": [
    "### Hugging Face API\n",
    "1. Create Hugging Face Account if not already exists.\n",
    "2. Create API Token\n",
    "3. Configure token in .env file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaaa6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2631be",
   "metadata": {},
   "source": [
    "Function: Load Model\n",
    "1. Given a model name\n",
    "2. From HF model hub, loads the model in memory.\n",
    "\n",
    "Note: \n",
    "1. When model is loaded it uses GPU / CPU based on avilable compute resources.\n",
    "2. By default, pytorch uses datatype of weights as FP32.\n",
    "3. On GPUs, loading models may fail if they exceed GPU memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"):\n",
    "    model_name = model_name\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, token=token)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b105e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8127f1e",
   "metadata": {},
   "source": [
    "BitsAndBytes Configuration to load the model. Here we are loading the model using 4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10cc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    bnb_4bit_quant_type='fp4'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45912d56",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b25107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:05<00:00, 16.40s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        # device_map=,\n",
    "        # ,  #! Dynamically balancing between CPU and GPU\n",
    "        quantization_config=quantification_config,  #! Quantization\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b9b4",
   "metadata": {},
   "source": [
    "Review the number of parameters and size of the model (7 GB as against the base model with 30 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96471af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameter: 8030261248 and approximate size of model 7 GBs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Model Parameter: {model.num_parameters()} and approximate size of model {round(model.num_parameters()*1/1024/1024/1024)} GBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d140f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.0.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.0.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.0.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.1.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.1.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.1.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.2.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.2.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.2.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.3.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.3.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.3.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.4.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.4.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.4.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.5.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.5.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.5.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.6.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.6.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.6.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.7.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.7.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.7.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.8.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.8.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.8.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.9.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.9.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.9.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.10.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.10.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.10.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.11.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.11.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.11.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.12.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.12.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.12.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.13.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.13.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.13.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.14.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.14.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.14.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.15.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.15.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.15.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.16.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.16.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.16.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.17.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.17.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.17.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.18.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.18.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.18.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.19.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.19.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.19.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.20.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.20.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.20.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.21.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.21.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.21.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.22.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.22.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.22.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.23.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.23.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.23.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.24.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.24.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.24.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.25.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.25.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.25.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.26.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.26.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.26.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.27.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.27.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.27.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.28.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.28.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.28.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.29.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.29.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.29.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.30.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.30.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.30.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.31.self_attn.q_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.k_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.v_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.self_attn.o_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.gate_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.up_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.mlp.down_proj.weight is loaded with torch.uint8 and device type cuda:0\n",
      "model.layers.31.input_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.layers.31.post_attention_layernorm.weight is loaded with torch.float16 and device type cuda:0\n",
      "model.norm.weight is loaded with torch.float16 and device type cuda:0\n",
      "lm_head.weight is loaded with torch.float16 and device type cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} is loaded with {param.dtype} and device type {param.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f02d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743903a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_response(\n",
    "        prompt:str,\n",
    "        tokenizer:AutoTokenizer,\n",
    "        model:AutoModelForCausalLM,\n",
    "        max_length:int=3500,\n",
    "        temperature:float=0.1,\n",
    "        top_k:int=50)->str:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\",padding=True)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = {k: v.to(device) for k, v in input_ids.items()}\n",
    "    print(inputs)\n",
    "    attention_mask = input_ids[\"attention_mask\"]\n",
    "    input_ids = input_ids[\"input_ids\"]\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    print(attention_mask[0])\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        output = model.generate(\n",
    "                                    **inputs, \n",
    "                                    max_length=max_length, \n",
    "                                    do_sample=True,\n",
    "                                    temperature=temperature, \n",
    "                                    top_k=top_k,\n",
    "                                    # attention_mask=attention_mask,\n",
    "                                    pad_token_id=pad_token_id,\n",
    "                                    eos_token_id=eos_token_id\n",
    "                                    )\n",
    "        final_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        print(final_output)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c52583a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000,   3923,    374,    279,   7438,    315,   2324,     30]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "What is the meaning of life? That's a big question. I think it's different for everyone. For me, I guess it's about finding purpose and meaning in what I do. Maybe it's about helping others or making a difference in some way. Or maybe it's about personal growth and self-actualization. I'm not entirely sure, but I think it's something that evolves over time as I experience different things and grow.\n",
      "But wait, is there a universal meaning of life? Or is it subjective? I remember hearing that different cultures have different answers. For example, some might say it's about family, others about achievement, and some about spirituality. So maybe the meaning isn't one-size-fits-all, but rather something personal that each individual has to discover for themselves.\n",
      "\n",
      "I also wonder if it's possible that the meaning of life isn't something we're supposed to figure out on our own. Maybe it's something that's given to us through our beliefs or the society we live in. Or perhaps it's a question that doesn't have a concrete answer, but rather is a journey of exploration.\n",
      "\n",
      "Another angle is looking at the bigger picture. Maybe the meaning of life is about our impact on the world or the legacy we leave behind. Or maybe it's about the experiences we collect and how we process them. It's like, what do we do with the time we have? How do we use our skills and talents? How do we contribute to the world in a meaningful way?\n",
      "\n",
      "I also think about the concept of purpose. Finding a purpose can give life meaning. For some, it's their job, for others, it's their hobbies or volunteer work. So maybe the meaning of life is tied to what we're passionate about and what we can contribute to make the world a better place.\n",
      "\n",
      "But then again, some people might not find their purpose early on, and that's okay too. Life is a journey, and maybe the meaning emerges over time as we go through different stages and experiences. It's like a puzzle where each piece is a different experience, and putting them together reveals the bigger picture.\n",
      "\n",
      "I also recall that some philosophical traditions have their take on the meaning of life. For example, existentialism suggests that we create our own meaning. So, maybe the meaning of life is something we have to define for ourselves. It's about how we choose to live and what values we prioritize.\n",
      "\n",
      "On the other hand, some religious or spiritual perspectives offer a predefined meaning, like serving a higher power or living according to certain moral principles. So, depending on one's beliefs, the meaning can vary widely.\n",
      "\n",
      "I'm also curious about how this question has been answered by notable figures or philosophers. I think some have written extensively on this, offering different perspectives. But in the end, it's subjective. Each person's life is unique, so their meaning of life is unique too.\n",
      "\n",
      "Moreover, I think about the idea of \"meaning\" itself. It's not just about what we do, but also about how we feel about what we do. The significance we attach to our actions and experiences. So, maybe the meaning of life is more about the emotional and psychological aspects of our lives rather than just the factual ones.\n",
      "\n",
      "In summary, the meaning of life seems to be a deeply personal and subjective concept. It's something each individual has to explore and define for themselves. It's not one answer fits all, but rather a journey of self-discovery and growth. The question itself might not have a definitive answer, but the process of seeking it can be fulfilling in itself.\n",
      "</think>\n",
      "\n",
      "The meaning of life is a deeply personal and subjective concept, unique to each individual. It is not a one-size-fits-all answer but rather a journey of self-discovery and growth. The process of seeking meaning can be fulfilling in itself, as individuals explore their passions, contributions, and personal growth. The meaning of life evolves over time, shaped by experiences and the emotional and psychological significance we attach to our actions and experiences. It can be found in purpose, passion, and personal growth, or defined by one's beliefs and societal context. Ultimately, the meaning of life is a journey of exploration and self-discovery, where each person defines their own path and significance.\n",
      "Time taken: 759.4572160243988\n"
     ]
    }
   ],
   "source": [
    "generate_model_response(\"What is the meaning of life?\", tokenizer=tokenizer, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
